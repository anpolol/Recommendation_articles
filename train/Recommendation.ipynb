{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/rusty1s/pyg_autoscale.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric_autoscale.models.base import ScalableGNN\n",
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "from torch.nn import ModuleList\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import to_undirected\n",
    "import json\n",
    "from uuid import UUID\n",
    "from base64 import b64decode as b64d\n",
    "import networkx as nx\n",
    "from Model import Scalable\n",
    "import pickle \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "def dataprocess(data): #удаление ребер для валидации \n",
    "        #splitting data to train and test\n",
    "        train_edge_index = []\n",
    "        val_edge_index = []\n",
    "        indices_to_delete_for_val  = np.random.choice(list(range(len(data.edge_index[0]))), int(len(data.edge_index[0])*0.2),replace=False)\n",
    "        l=0\n",
    "        for i,x in enumerate(list(zip(*data.edge_index.tolist()))):\n",
    "            l+=1\n",
    "            if i in indices_to_delete_for_val: \n",
    "                val_edge_index.append(x)\n",
    "            else: \n",
    "                train_edge_index.append(x)\n",
    "                \n",
    "        val_edge_index = torch.tensor(np.array(list(zip(*val_edge_index))))\n",
    "        train_edge_index = torch.tensor(np.array(list(zip(*train_edge_index))), dtype = torch.long)\n",
    "        \n",
    "        s = set(itertools.combinations(range(len(data.x)), 2))\n",
    "        \n",
    "        s_of_edges = set()\n",
    "        \n",
    "        for pair in (data.edge_index.t().tolist()):\n",
    "            s_of_edges.add(tuple(pair))\n",
    "        s_of_non_edges = s - s_of_edges\n",
    "        \n",
    "        #append negative samples to test set\n",
    "        non_edges=[]\n",
    "        for pair in list(s_of_non_edges):\n",
    "            non_edges.append(list(pair))\n",
    "        non_edges_val=torch.tensor(random.choices(non_edges, k = len(val_edge_index[0]))).t()\n",
    "        y_true_val = [1]*len(val_edge_index[0])\n",
    "        val_edge_index=torch.cat((val_edge_index,non_edges_val),1)\n",
    "        y_true_val += [0]*len(non_edges_val[0])\n",
    "        data.edge_index = train_edge_index\n",
    "        \n",
    "        return data,non_edges_val,val_edge_index,y_true_val #data уже обрезанная по ребрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(): #загрузить и обработать данные\n",
    "   # with open('assets (16)','r', encoding=\"utf-8\") as f:\n",
    "    #    assets = json.load(f)\n",
    "\n",
    "    with open('embeddings.json','r') as f:\n",
    "        emb_map = json.load(f)\n",
    "\n",
    "    to_uuid = lambda x: str(UUID(b64d(x, altchars=None, validate=False).hex()))\n",
    "    \n",
    "    #rels = []\n",
    "    rels = pd.read_csv('relations.csv')\n",
    "    rels=list(zip(list(rels['from']),list(rels['to'])))\n",
    "    #for asset in assets:\n",
    "     #   if asset['cited_articles']:\n",
    "      #      source = to_uuid(asset['asset_id']['$binary'])\n",
    "       #     for tt in  asset['cited_articles']:\n",
    "        #        target = to_uuid(tt['$binary'])\n",
    "         #       rels.append(tuple([source,target]))\n",
    "\n",
    "    rels = [x for x in rels if x[0] in emb_map and x[1] in emb_map]\n",
    "    mapping_old_to_new={}\n",
    "    mapping_new_to_old = {}\n",
    "    \n",
    "    for id_new,id_old in enumerate(emb_map):\n",
    "            mapping_old_to_new[id_old] = id_new\n",
    "            mapping_new_to_old[id_new] = id_old\n",
    "            \n",
    "    x = []\n",
    "    for id_new,id_old in enumerate(emb_map):\n",
    "        x.append(emb_map[id_old]) \n",
    "        \n",
    "    edges = list(map(lambda edge: [mapping_old_to_new[edge[0]], mapping_old_to_new[edge[1]]], rels)) \n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges) #чтоб граф точно был направленным, в Graph ребра в одну сторону выписываются, хотя и считаются ненаправленными\n",
    "    \n",
    "    data_init = Data(x=torch.tensor(x),edge_index = torch.tensor(list(G.edges)).t() ) #тут все ребра\n",
    "    return  data_init,mapping_new_to_old,mapping_old_to_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_to_undirected(data):\n",
    "    data.edge_index=to_undirected(data.edge_index)\n",
    "    data.adj_t=SparseTensor(row=data.edge_index[0],col=data.edge_index[1],sparse_sizes=(len(data.x),len(data.x)))\n",
    "    #SparseTensor.from_edge_index(data.edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_init, mapping_new_to_old,mapping_old_to_new=data_load() #data_init - это самый изначальный граф, маппинги вершин\n",
    "\n",
    "#data,non_edges_val,val_edge_index,y_true_val = dataprocess(data_init) #data - здесь уже без части ребер, для валидации надо\n",
    "#data = di_to_undirected(data)#добавление ребер в обратную сторону\n",
    "data=data_init\n",
    "data_init = di_to_undirected(data_init)#добавление ребер в обратную сторону\n",
    "data=di_to_undirected(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning with 40 parts... Done! [0.07s]\n",
      "Permuting data... Done! [0.02s]\n",
      "Pre-processing subgraphs... Done! [0.02s]\n"
     ]
    }
   ],
   "source": [
    "perm, ptr = metis(data.adj_t, num_parts=40, log=True)\n",
    "data_train = permute(data, perm, log=True)\n",
    "loader = SubgraphLoader(data_train, ptr, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_samples(edge_index,ind,num_negative_samples): #возвращает негативные примеры\n",
    "    d=datetime.now()\n",
    "    neg_samples=torch.Tensor(size=(len(ind),num_negative_samples+1))\n",
    "    neg_samples.t()[0] = ind\n",
    "    for i in ind:\n",
    "        d=datetime.now()\n",
    "        neig=(edge_index[1][(edge_index[0]==i).nonzero(as_tuple=True)[0]])\n",
    "        neg_neigbors=ind[~ind.unsqueeze(1).eq(neig).any(1)] #difference between all indices and neighbors\n",
    "        neg_neigbors=(neg_neigbors[(neg_neigbors!=i).nonzero(as_tuple=True)[0]])\n",
    "        #probs = torch.zeros(max(neg_neigbors)+1)\n",
    "        d=datetime.now()\n",
    "        #probs[neg_neigbors]=1\n",
    "        d = datetime.now()\n",
    "        neg_samples[i][1:]=torch.tensor(np.random.choice(neg_neigbors,num_negative_samples))\n",
    "        \n",
    "    \n",
    "    return neg_samples\n",
    "\n",
    "def edge_index(batch,size): #выбираются ребра только для батча и только для вершин внутри батча\n",
    "    adj=batch.adj_t\n",
    "    t=(adj.to_torch_sparse_coo_tensor()).coalesce()\n",
    "    ind = torch.tensor(range(size))\n",
    "    edge_index = t.indices()\n",
    "    first=((edge_index[0]<len(ind)).nonzero(as_tuple=True)[0])\n",
    "    second=((edge_index[1]<len(ind)).nonzero(as_tuple=True)[0])\n",
    "    new_indices=(torch.tensor(np.intersect1d(first,second)))\n",
    "    edge_index1 =  edge_index[0][new_indices]\n",
    "    edge_index2 = edge_index[1][new_indices]\n",
    "    return (torch.stack([edge_index1, edge_index2], dim=0)),ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader,num_negative_smples):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch,*args in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x[:args[0]], batch.adj_t,*args)\n",
    "        e_index,ind=edge_index(batch,args[0])\n",
    "        pos = e_index.t()\n",
    "        neg = neg_samples(e_index,ind,num_negative_smples)\n",
    "        samples = (pos,neg)\n",
    "\n",
    "        loss = model.loss(out, samples)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        total_loss+=loss\n",
    "    return total_loss/len(loader)\n",
    "def test(y_true,model,data,val_edge_index):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.adj_t)\n",
    "\n",
    "    y_pred = []\n",
    "    for x in list(zip(*val_edge_index)):\n",
    "        y_pred.append(float(torch.sigmoid(torch.dot(out[x[0]],out[x[1]]))))#print(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))\n",
    "    \n",
    "    return roc_auc_score(y_true,torch.tensor(y_pred).detach().numpy()) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(1.0558, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.749990\n",
      "11 tensor(1.0483, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.776546\n",
      "12 tensor(1.0487, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.780576\n",
      "13 tensor(1.0445, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.784029\n",
      "14 tensor(1.0437, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.814721\n",
      "15 tensor(1.0400, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.805497\n",
      "16 tensor(1.0387, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.794397\n",
      "17 tensor(1.0375, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.802732\n",
      "18 tensor(1.0353, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.831237\n",
      "19 tensor(1.0330, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.852543\n",
      "20 tensor(1.0319, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.847101\n",
      "21 tensor(1.0309, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.882887\n",
      "22 tensor(1.0295, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.850665\n",
      "23 tensor(1.0264, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.848076\n",
      "24 tensor(1.0244, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.857710\n",
      "25 tensor(1.0248, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.838552\n",
      "26 tensor(1.0213, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.882328\n",
      "27 tensor(1.0197, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.853124\n",
      "28 tensor(1.0184, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.872156\n",
      "29 tensor(1.0178, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.867376\n",
      "30 tensor(1.0162, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.838341\n",
      "31 tensor(1.0138, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.840231\n",
      "32 tensor(1.0136, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.859233\n",
      "33 tensor(1.0109, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.871318\n",
      "34 tensor(1.0102, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.870914\n",
      "35 tensor(1.0072, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.884701\n",
      "36 tensor(1.0077, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.844862\n",
      "37 tensor(1.0057, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.921678\n",
      "38 tensor(1.0026, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.920544\n",
      "39 tensor(1.0039, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.934576\n",
      "40 tensor(1.0020, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.974515\n",
      "41 tensor(1.0004, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.930715\n",
      "42 tensor(1.0018, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.016909\n",
      "43 tensor(1.0000, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.924910\n",
      "44 tensor(0.9966, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.962689\n",
      "45 tensor(0.9977, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.959093\n",
      "46 tensor(0.9966, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.959454\n",
      "47 tensor(0.9942, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.991306\n",
      "48 tensor(0.9921, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.024116\n",
      "49 tensor(0.9930, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.989195\n",
      "50 tensor(0.9919, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.020810\n",
      "51 tensor(0.9893, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.030197\n",
      "52 tensor(0.9888, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.030190\n",
      "53 tensor(0.9896, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.091201\n",
      "54 tensor(0.9887, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.133210\n",
      "55 tensor(0.9869, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.168181\n",
      "56 tensor(0.9851, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.163713\n",
      "57 tensor(0.9857, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.165010\n",
      "58 tensor(0.9833, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.049343\n",
      "59 tensor(0.9839, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.029059\n",
      "60 tensor(0.9824, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.023062\n",
      "61 tensor(0.9836, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.037120\n",
      "62 tensor(0.9833, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.023243\n",
      "63 tensor(0.9810, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.045739\n",
      "64 tensor(0.9795, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.031233\n",
      "65 tensor(0.9814, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.045237\n",
      "66 tensor(0.9798, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.082863\n",
      "67 tensor(0.9781, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.087006\n",
      "68 tensor(0.9775, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.051829\n",
      "69 tensor(0.9783, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.040363\n",
      "70 tensor(0.9770, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.107518\n",
      "71 tensor(0.9745, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.103908\n",
      "72 tensor(0.9753, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.016055\n",
      "73 tensor(0.9733, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.039937\n",
      "74 tensor(0.9727, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.021415\n",
      "75 tensor(0.9742, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.018448\n",
      "76 tensor(0.9713, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.010095\n",
      "77 tensor(0.9720, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.988231\n",
      "78 tensor(0.9702, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.999156\n",
      "79 tensor(0.9696, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.989224\n",
      "80 tensor(0.9701, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.990990\n",
      "81 tensor(0.9692, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.957844\n",
      "82 tensor(0.9673, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.004142\n",
      "83 tensor(0.9682, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.965690\n",
      "84 tensor(0.9692, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.953834\n",
      "85 tensor(0.9680, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.950453\n",
      "86 tensor(0.9670, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.922625\n",
      "87 tensor(0.9653, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.931608\n",
      "88 tensor(0.9670, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.939668\n",
      "89 tensor(0.9662, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.922292\n",
      "90 tensor(0.9634, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.963268\n",
      "91 tensor(0.9631, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.918518\n",
      "92 tensor(0.9650, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.924458\n",
      "93 tensor(0.9640, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.923206\n",
      "94 tensor(0.9622, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.914883\n",
      "95 tensor(0.9625, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.883634\n",
      "96 tensor(0.9618, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.927137\n",
      "97 tensor(0.9631, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.955472\n",
      "98 tensor(0.9599, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.988190\n",
      "99 tensor(0.9597, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.877765\n",
      "100 tensor(0.9593, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.909708\n",
      "101 tensor(0.9592, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.898115\n",
      "102 tensor(0.9590, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.917635\n",
      "103 tensor(0.9566, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.936471\n",
      "104 tensor(0.9594, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.936335\n",
      "105 tensor(0.9563, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.881201\n",
      "106 tensor(0.9586, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.994953\n",
      "107 tensor(0.9586, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.910795\n",
      "108 tensor(0.9567, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.938924\n",
      "109 tensor(0.9559, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.961585\n",
      "110 tensor(0.9565, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.928963\n",
      "111 tensor(0.9549, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.876529\n",
      "112 tensor(0.9547, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.950534\n",
      "113 tensor(0.9537, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.900461\n",
      "114 tensor(0.9534, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.882143\n",
      "115 tensor(0.9542, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.890373\n",
      "116 tensor(0.9541, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.900490\n",
      "117 tensor(0.9525, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.917835\n",
      "118 tensor(0.9516, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.890551\n",
      "119 tensor(0.9532, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.891410\n",
      "120 tensor(0.9514, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.891142\n",
      "121 tensor(0.9513, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.901625\n",
      "122 tensor(0.9510, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.867753\n",
      "123 tensor(0.9499, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.874553\n",
      "124 tensor(0.9478, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.989040\n",
      "125 tensor(0.9511, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.897654\n",
      "126 tensor(0.9506, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.898990\n",
      "127 tensor(0.9488, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.865645\n",
      "128 tensor(0.9490, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.871079\n",
      "129 tensor(0.9470, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.873671\n",
      "130 tensor(0.9488, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.907804\n",
      "131 tensor(0.9485, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.885494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 tensor(0.9479, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.878730\n",
      "133 tensor(0.9472, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.914731\n",
      "134 tensor(0.9467, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.942281\n",
      "135 tensor(0.9485, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.923121\n",
      "136 tensor(0.9469, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.903321\n",
      "137 tensor(0.9482, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.896270\n",
      "138 tensor(0.9459, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.892500\n",
      "139 tensor(0.9453, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.912996\n",
      "140 tensor(0.9449, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.899082\n",
      "141 tensor(0.9464, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.881924\n",
      "142 tensor(0.9438, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.872775\n",
      "143 tensor(0.9430, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.903909\n",
      "144 tensor(0.9426, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.919999\n",
      "145 tensor(0.9446, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.903026\n",
      "146 tensor(0.9422, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.918234\n",
      "147 tensor(0.9421, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.909630\n",
      "148 tensor(0.9427, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.955459\n",
      "149 tensor(0.9434, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.934140\n",
      "150 tensor(0.9419, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.956410\n",
      "151 tensor(0.9393, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.957000\n",
      "152 tensor(0.9430, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.972452\n",
      "153 tensor(0.9400, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:02.987508\n",
      "154 tensor(0.9405, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.019592\n",
      "155 tensor(0.9400, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.014590\n",
      "156 tensor(0.9408, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.101925\n",
      "157 tensor(0.9404, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.033395\n",
      "158 tensor(0.9390, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.076260\n",
      "159 tensor(0.9396, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.135168\n",
      "160 tensor(0.9377, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.133887\n",
      "161 tensor(0.9396, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.115315\n",
      "162 tensor(0.9383, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.120270\n",
      "163 tensor(0.9385, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.137398\n",
      "164 tensor(0.9398, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.142053\n",
      "165 tensor(0.9373, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.158022\n",
      "166 tensor(0.9363, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.158076\n",
      "167 tensor(0.9382, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.145869\n",
      "168 tensor(0.9362, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.157731\n",
      "169 tensor(0.9374, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.137478\n",
      "170 tensor(0.9363, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.133164\n",
      "171 tensor(0.9359, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.119784\n",
      "172 tensor(0.9335, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.147937\n",
      "173 tensor(0.9366, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.134991\n",
      "174 tensor(0.9343, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.148525\n",
      "175 tensor(0.9342, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.209291\n",
      "176 tensor(0.9351, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.278803\n",
      "177 tensor(0.9341, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.208726\n",
      "178 tensor(0.9343, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.164870\n",
      "179 tensor(0.9351, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.331994\n",
      "180 tensor(0.9350, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.230179\n",
      "181 tensor(0.9355, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.281930\n",
      "182 tensor(0.9332, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.212613\n",
      "183 tensor(0.9334, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.220982\n",
      "184 tensor(0.9339, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.223258\n",
      "185 tensor(0.9322, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.196715\n",
      "186 tensor(0.9325, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.215868\n",
      "187 tensor(0.9310, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.224744\n",
      "188 tensor(0.9324, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.224792\n",
      "189 tensor(0.9309, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.201019\n",
      "190 tensor(0.9317, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.379870\n",
      "191 tensor(0.9297, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.388182\n",
      "192 tensor(0.9299, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.172891\n",
      "193 tensor(0.9303, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.182321\n",
      "194 tensor(0.9297, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.214814\n",
      "195 tensor(0.9309, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.191909\n",
      "196 tensor(0.9281, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.214651\n",
      "197 tensor(0.9300, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.170859\n",
      "198 tensor(0.9281, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.199127\n",
      "199 tensor(0.9279, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.168668\n",
      "200 tensor(0.9294, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.174522\n",
      "201 tensor(0.9294, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.216220\n",
      "202 tensor(0.9295, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.243745\n",
      "203 tensor(0.9280, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.213726\n",
      "204 tensor(0.9298, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.202576\n",
      "205 tensor(0.9288, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.236151\n",
      "206 tensor(0.9273, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.184714\n",
      "207 tensor(0.9273, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.215332\n",
      "208 tensor(0.9283, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.258458\n",
      "209 tensor(0.9288, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.266371\n",
      "210 tensor(0.9275, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.241698\n",
      "211 tensor(0.9270, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.221468\n",
      "212 tensor(0.9256, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.201304\n",
      "213 tensor(0.9269, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.251359\n",
      "214 tensor(0.9259, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.240731\n",
      "215 tensor(0.9255, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.225722\n",
      "216 tensor(0.9253, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.230767\n",
      "217 tensor(0.9257, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.247356\n",
      "218 tensor(0.9259, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.257668\n",
      "219 tensor(0.9244, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.409053\n",
      "220 tensor(0.9244, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.404667\n",
      "221 tensor(0.9238, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.253597\n",
      "222 tensor(0.9249, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.347476\n",
      "223 tensor(0.9230, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.194170\n",
      "224 tensor(0.9236, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.194843\n",
      "225 tensor(0.9243, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.192186\n",
      "226 tensor(0.9245, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.204724\n",
      "227 tensor(0.9229, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.192694\n",
      "228 tensor(0.9236, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.207381\n",
      "229 tensor(0.9217, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.208216\n",
      "230 tensor(0.9252, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.211350\n",
      "231 tensor(0.9223, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.219901\n",
      "232 tensor(0.9250, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.201860\n",
      "233 tensor(0.9218, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.217418\n",
      "234 tensor(0.9236, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.212168\n",
      "235 tensor(0.9219, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.197992\n",
      "236 tensor(0.9205, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.207141\n",
      "237 tensor(0.9200, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.207545\n",
      "238 tensor(0.9216, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.302732\n",
      "239 tensor(0.9206, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.203410\n",
      "240 tensor(0.9210, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.213178\n",
      "241 tensor(0.9219, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.218061\n",
      "242 tensor(0.9198, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.198510\n",
      "243 tensor(0.9218, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.190334\n",
      "244 tensor(0.9203, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.199548\n",
      "245 tensor(0.9198, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.185347\n",
      "246 tensor(0.9193, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.215506\n",
      "247 tensor(0.9199, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.210662\n",
      "248 tensor(0.9197, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.248278\n",
      "249 tensor(0.9195, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.230162\n",
      "250 tensor(0.9191, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.208937\n",
      "251 tensor(0.9200, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.199296\n",
      "252 tensor(0.9201, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.195987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 tensor(0.9200, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.223125\n",
      "254 tensor(0.9202, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.216258\n",
      "255 tensor(0.9172, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.218853\n",
      "256 tensor(0.9186, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.216626\n",
      "257 tensor(0.9186, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.237727\n",
      "258 tensor(0.9196, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.268512\n",
      "259 tensor(0.9177, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.224802\n",
      "260 tensor(0.9169, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.226350\n",
      "261 tensor(0.9210, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.241924\n",
      "262 tensor(0.9177, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.225106\n",
      "263 tensor(0.9184, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.241149\n",
      "264 tensor(0.9171, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.257741\n",
      "265 tensor(0.9173, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.355628\n",
      "266 tensor(0.9163, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.268213\n",
      "267 tensor(0.9172, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.353501\n",
      "268 tensor(0.9156, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.328938\n",
      "269 tensor(0.9166, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.267846\n",
      "270 tensor(0.9162, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.267500\n",
      "271 tensor(0.9181, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.253613\n",
      "272 tensor(0.9172, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.273241\n",
      "273 tensor(0.9158, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.337625\n",
      "274 tensor(0.9164, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.302923\n",
      "275 tensor(0.9167, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.295585\n",
      "276 tensor(0.9151, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.272601\n",
      "277 tensor(0.9158, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.358573\n",
      "278 tensor(0.9157, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.320430\n",
      "279 tensor(0.9158, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.280235\n",
      "280 tensor(0.9150, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.299739\n",
      "281 tensor(0.9150, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.359451\n",
      "282 tensor(0.9143, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.277760\n",
      "283 tensor(0.9154, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.300614\n",
      "284 tensor(0.9147, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.259110\n",
      "285 tensor(0.9139, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.257702\n",
      "286 tensor(0.9127, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.257556\n",
      "287 tensor(0.9131, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.257466\n",
      "288 tensor(0.9122, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.255008\n",
      "289 tensor(0.9144, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.270213\n",
      "290 tensor(0.9136, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.244212\n",
      "291 tensor(0.9135, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.246936\n",
      "292 tensor(0.9126, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.238481\n",
      "293 tensor(0.9119, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.296193\n",
      "294 tensor(0.9130, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.314416\n",
      "295 tensor(0.9119, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.297683\n",
      "296 tensor(0.9149, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.463452\n",
      "297 tensor(0.9116, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.334609\n",
      "298 tensor(0.9110, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.274259\n",
      "299 tensor(0.9131, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.322252\n",
      "300 tensor(0.9145, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.327180\n",
      "301 tensor(0.9134, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.291949\n",
      "302 tensor(0.9129, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.405521\n",
      "303 tensor(0.9116, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.292067\n",
      "304 tensor(0.9101, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.297287\n",
      "305 tensor(0.9126, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.297490\n",
      "306 tensor(0.9097, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.270807\n",
      "307 tensor(0.9107, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.281496\n",
      "308 tensor(0.9090, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.305174\n",
      "309 tensor(0.9103, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.283494\n",
      "310 tensor(0.9096, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.272974\n",
      "311 tensor(0.9105, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.330408\n",
      "312 tensor(0.9104, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.444486\n",
      "313 tensor(0.9103, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.352786\n",
      "314 tensor(0.9093, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.412869\n",
      "315 tensor(0.9095, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.321018\n",
      "316 tensor(0.9094, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.377988\n",
      "317 tensor(0.9081, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.335781\n",
      "318 tensor(0.9092, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.313832\n",
      "319 tensor(0.9081, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.316260\n",
      "320 tensor(0.9085, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.324412\n",
      "321 tensor(0.9071, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.442046\n",
      "322 tensor(0.9079, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.346126\n",
      "323 tensor(0.9085, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.348405\n",
      "324 tensor(0.9088, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.331265\n",
      "325 tensor(0.9074, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.377302\n",
      "326 tensor(0.9087, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.363802\n",
      "327 tensor(0.9077, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.316724\n",
      "328 tensor(0.9086, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.305544\n",
      "329 tensor(0.9079, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.295076\n",
      "330 tensor(0.9101, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.308546\n",
      "331 tensor(0.9078, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.331468\n",
      "332 tensor(0.9097, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.388813\n",
      "333 tensor(0.9058, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.485728\n",
      "334 tensor(0.9059, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.460118\n",
      "335 tensor(0.9054, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.370801\n",
      "336 tensor(0.9059, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.395842\n",
      "337 tensor(0.9055, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.474559\n",
      "338 tensor(0.9084, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.362439\n",
      "339 tensor(0.9043, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.356542\n",
      "340 tensor(0.9055, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.334835\n",
      "341 tensor(0.9069, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.340946\n",
      "342 tensor(0.9077, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.416309\n",
      "343 tensor(0.9051, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.363145\n",
      "344 tensor(0.9052, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.344026\n",
      "345 tensor(0.9052, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.409308\n",
      "346 tensor(0.9059, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.379287\n",
      "347 tensor(0.9064, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.484379\n",
      "348 tensor(0.9066, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.338082\n",
      "349 tensor(0.9081, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.362125\n",
      "350 tensor(0.9053, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.358136\n",
      "351 tensor(0.9054, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.394811\n",
      "352 tensor(0.9057, grad_fn=<DivBackward0>)\n",
      "one epoch 0:00:03.415525\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.512339\n"
     ]
    }
   ],
   "source": [
    "d = datetime.now()\n",
    "#model = Scalable(num_nodes=len(data_init.x), in_channels=len(data_init.x[0]), hidden_channels=128,out_channels=128, num_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay = 1e-5)\n",
    "schedular  = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "num_negative_smples=4\n",
    "#losses=[]\n",
    "scores=[]\n",
    "for epoch in range(10,353):\n",
    "        d=datetime.now()\n",
    "        loss=train(model,loader,num_negative_smples)\n",
    "        losses.append(float(loss))\n",
    "        print(epoch,loss)\n",
    "        #scheduler.step(loss)\n",
    "        #score=test(y_true_val,model,data,val_edge_index)\n",
    "        #scores.append(score)\n",
    "        print('one epoch',datetime.now()-d)\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "#plt.plot(torch.tensor(scores).tolist())\n",
    "#plt.show()\n",
    "print(datetime.now()-d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model_parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сам инференс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### принимает параметры: \n",
    "* vertex = tuple(id, text_emb)\n",
    "\n",
    "* neighbors = [(id, text_emb), (..)] (list of tuples)\n",
    "\n",
    "* neighbors_of_neighbors = [(id, text_emb), (..)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "x=model.inference(new_vertices,old_vertices,rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = igraph.Graph.TupleList(rels, weights=False, directed=True)\n",
    "igraph.summary(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import math\n",
    "# plot tree\n",
    "init_notebook_mode()\n",
    "def plot(G, annotations=False):\n",
    "\n",
    "    lay = G.layout_fruchterman_reingold(grid=\"nogrid\", niter=1000)\n",
    "    nr_vertices = len(G.vs)\n",
    "    position = {k: lay[k] for k in range(nr_vertices)}\n",
    "    Y = [lay[k][1] for k in range(nr_vertices)]\n",
    "    M = max(Y)\n",
    "    labels = [x['name'] for x in G.vs()]\n",
    "    es = igraph.EdgeSeq(G) # sequence of edges\n",
    "    E = [e.tuple for e in G.es] # list of edges\n",
    "\n",
    "    L = len(position)\n",
    "    Xn = [position[k][0] for k in range(L)]\n",
    "    Yn = [2*M-position[k][1] for k in range(L)]\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    for edge in E:\n",
    "        Xe+=[position[edge[0]][0],position[edge[1]][0], None]\n",
    "        Ye+=[2*M-position[edge[0]][1],2*M-position[edge[1]][1], None] \n",
    "\n",
    "\n",
    "    #Create Plotly Traces\n",
    "\n",
    "    lines = go.Scatter(x=Xe,\n",
    "                       y=Ye,\n",
    "                       mode='lines',\n",
    "                       line=dict(color='rgb(210,210,210)', width=1),\n",
    "                       hoverinfo='none'\n",
    "                       )\n",
    "    dots = go.Scatter(x=Xn,\n",
    "                      y=Yn,\n",
    "                      mode='markers',\n",
    "                      name='',\n",
    "                      marker=dict(  colorbar=dict(\n",
    "                                        title=\"Modularity\"\n",
    "                                    ),\n",
    "                                    colorscale=\"Viridis\",\n",
    "                                    \n",
    "                                  \n",
    "                                    line=dict(color='rgb(50,50,50)', width=1)\n",
    "                                    ),\n",
    "                      \n",
    "                      hoverinfo='text',\n",
    "                      opacity=0.8\n",
    "                      )\n",
    "\n",
    "    # Create Text Inside the Circle via Annotations\n",
    "\n",
    "    def make_annotations(pos, text, font_size=10, \n",
    "                         font_color='rgb(0,0,0)'):\n",
    "        L=len(pos)\n",
    "        if len(text)!=L:\n",
    "            raise ValueError('The lists pos and text must have the same len')\n",
    "        annotations = go.Annotations()\n",
    "        for k in range(L):\n",
    "            annotations.append(\n",
    "                go.Annotation(\n",
    "                    text=labels[k], # or replace labels with a different list \n",
    "                                    # for the text within the circle  \n",
    "                    x=pos[k][0], y=2*M-position[k][1],\n",
    "                    xref='x1', yref='y1',\n",
    "                    font=dict(color=font_color, size=font_size),\n",
    "                    showarrow=False)\n",
    "            )\n",
    "        return annotations  \n",
    "\n",
    "    # Add Axis Specifications and Create the Layout\n",
    "\n",
    "    axis = dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "                zeroline=False,\n",
    "                showgrid=False,\n",
    "                showticklabels=False,\n",
    "                )\n",
    "    ann = []\n",
    "    if annotations:\n",
    "        ann = make_annotations(position, labels)\n",
    "    layout = dict(#title= 'Tree with Reingold-Tilford Layout',  \n",
    "                  height=900,\n",
    "                  annotations=ann,\n",
    "                  font=dict(size=12),\n",
    "                  showlegend=False,\n",
    "                  xaxis=go.XAxis(axis),\n",
    "                  yaxis=go.YAxis(axis),          \n",
    "                  margin=dict(l=40, r=40, b=85, t=100),\n",
    "                  hovermode='closest',\n",
    "                  plot_bgcolor='rgb(248,248,248)'          \n",
    "                  )\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    data=go.Data([lines, dots])\n",
    "    fig=dict(data=data, layout=layout)\n",
    "    #fig['layout'].update(annotations=make_annotations(position, labels))\n",
    "    iplot(fig, filename='Tree-Reingold-Tilf')\n",
    "    # use py.plot instead of py.iplot if you're not using a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna todo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "        data,mapping_new_to_old=data_loader()\n",
    "        print(data)\n",
    "        perm, ptr = metis(data.adj_t, num_parts=40, log=True)\n",
    "        data_train = permute(data, perm, log=True)\n",
    "        loader = SubgraphLoader(data_train, ptr, batch_size=10, shuffle=True)\n",
    "        len(loader)\n",
    "\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [64,128])\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [2,3])\n",
    "        num_negative_samples=trial.suggest_categorical('num neg samples', [1,2,3,4,5,6,7,8,9,10])\n",
    "        model = Scalable(num_nodes=len(data.x), in_channels=len(data.x[0]), hidden_channels=hidden_layer,out_channels=out_layer, num_layers=size)\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-4,1e-2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        for epoch in range(50):\n",
    "            loss = train(model,loader,num_negative_smples)\n",
    "        score=test(y_true_val,model,data,val_edge_index)\n",
    "        \n",
    "        trial.report(score,epoch)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective,n_trials = 20)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(\" Value: \", trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\" {}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
