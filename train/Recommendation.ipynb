{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "#!pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/rusty1s/pyg_autoscale.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric_autoscale.models.base import ScalableGNN\n",
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "from torch.nn import ModuleList\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import to_undirected\n",
    "import json\n",
    "from uuid import UUID\n",
    "from base64 import b64decode as b64d\n",
    "import networkx as nx\n",
    "from Model import Scalable\n",
    "import pickle \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "def dataprocess(data): #удаление ребер для валидации \n",
    "        #splitting data to train and test\n",
    "        train_edge_index = []\n",
    "        val_edge_index = []\n",
    "        indices_to_delete_for_val  = np.random.choice(list(range(len(data.edge_index[0]))), int(len(data.edge_index[0])*0.2),replace=False)\n",
    "        l=0\n",
    "        for i,x in enumerate(list(zip(*data.edge_index.tolist()))):\n",
    "            l+=1\n",
    "            if i in indices_to_delete_for_val: \n",
    "                val_edge_index.append(x)\n",
    "            else: \n",
    "                train_edge_index.append(x)\n",
    "                \n",
    "        val_edge_index = torch.tensor(np.array(list(zip(*val_edge_index))))\n",
    "        train_edge_index = torch.tensor(np.array(list(zip(*train_edge_index))), dtype = torch.long)\n",
    "        \n",
    "        s = set(itertools.combinations(range(len(data.x)), 2))\n",
    "        \n",
    "        s_of_edges = set()\n",
    "        \n",
    "        for pair in (data.edge_index.t().tolist()):\n",
    "            s_of_edges.add(tuple(pair))\n",
    "        s_of_non_edges = s - s_of_edges\n",
    "        \n",
    "        #append negative samples to test set\n",
    "        non_edges=[]\n",
    "        for pair in list(s_of_non_edges):\n",
    "            non_edges.append(list(pair))\n",
    "        non_edges_val=torch.tensor(random.choices(non_edges, k = len(val_edge_index[0]))).t()\n",
    "        y_true_val = [1]*len(val_edge_index[0])\n",
    "        val_edge_index=torch.cat((val_edge_index,non_edges_val),1)\n",
    "        y_true_val += [0]*len(non_edges_val[0])\n",
    "        data.edge_index = train_edge_index\n",
    "        \n",
    "        return data,non_edges_val,val_edge_index,y_true_val #data уже обрезанная по ребрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(): #загрузить и обработать данные\n",
    "   # with open('assets (16)','r', encoding=\"utf-8\") as f:\n",
    "    #    assets = json.load(f)\n",
    "\n",
    "    with open('embeddings.json','r') as f:\n",
    "        emb_map = json.load(f)\n",
    "\n",
    "    to_uuid = lambda x: str(UUID(b64d(x, altchars=None, validate=False).hex()))\n",
    "    \n",
    "    #rels = []\n",
    "    rels = pd.read_csv('relations.csv')\n",
    "    rels=list(zip(list(rels['from']),list(rels['to'])))\n",
    "    #for asset in assets:\n",
    "     #   if asset['cited_articles']:\n",
    "      #      source = to_uuid(asset['asset_id']['$binary'])\n",
    "       #     for tt in  asset['cited_articles']:\n",
    "        #        target = to_uuid(tt['$binary'])\n",
    "         #       rels.append(tuple([source,target]))\n",
    "\n",
    "    rels = [x for x in rels if x[0] in emb_map and x[1] in emb_map]\n",
    "    mapping_old_to_new={}\n",
    "    mapping_new_to_old = {}\n",
    "    \n",
    "    for id_new,id_old in enumerate(emb_map):\n",
    "            mapping_old_to_new[id_old] = id_new\n",
    "            mapping_new_to_old[id_new] = id_old\n",
    "            \n",
    "    x = []\n",
    "    for id_new,id_old in enumerate(emb_map):\n",
    "        x.append(emb_map[id_old]) \n",
    "        \n",
    "    edges = list(map(lambda edge: [mapping_old_to_new[edge[0]], mapping_old_to_new[edge[1]]], rels)) \n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges) #чтоб граф точно был направленным, в Graph ребра в одну сторону выписываются, хотя и считаются ненаправленными\n",
    "    \n",
    "    data_init = Data(x=torch.tensor(x),edge_index = torch.tensor(list(G.edges)).t() ) #тут все ребра\n",
    "    return  data_init,mapping_new_to_old,mapping_old_to_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_to_undirected(data):\n",
    "    data.edge_index=to_undirected(data.edge_index)\n",
    "    data.adj_t=SparseTensor(row=data.edge_index[0],col=data.edge_index[1],sparse_sizes=(len(data.x),len(data.x)))\n",
    "    #SparseTensor.from_edge_index(data.edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_init, mapping_new_to_old,mapping_old_to_new=data_load() #data_init - это самый изначальный граф, маппинги вершин\n",
    "\n",
    "#data,non_edges_val,val_edge_index,y_true_val = dataprocess(data_init) #data - здесь уже без части ребер, для валидации надо\n",
    "#data = di_to_undirected(data)#добавление ребер в обратную сторону\n",
    "data=data_init\n",
    "data_init = di_to_undirected(data_init)#добавление ребер в обратную сторону\n",
    "data=di_to_undirected(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm, ptr = metis(data.adj_t, num_parts=40, log=True)\n",
    "data_train = permute(data, perm, log=True)\n",
    "loader = SubgraphLoader(data_train, ptr, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_samples(edge_index,ind,num_negative_samples): #возвращает негативные примеры\n",
    "    d=datetime.now()\n",
    "    neg_samples=torch.Tensor(size=(len(ind),num_negative_samples+1))\n",
    "    neg_samples.t()[0] = ind\n",
    "    for i in ind:\n",
    "        d=datetime.now()\n",
    "        neig=(edge_index[1][(edge_index[0]==i).nonzero(as_tuple=True)[0]])\n",
    "        neg_neigbors=ind[~ind.unsqueeze(1).eq(neig).any(1)] #difference between all indices and neighbors\n",
    "        neg_neigbors=(neg_neigbors[(neg_neigbors!=i).nonzero(as_tuple=True)[0]])\n",
    "        #probs = torch.zeros(max(neg_neigbors)+1)\n",
    "        d=datetime.now()\n",
    "        #probs[neg_neigbors]=1\n",
    "        d = datetime.now()\n",
    "        neg_samples[i][1:]=torch.tensor(np.random.choice(neg_neigbors,num_negative_samples))\n",
    "        \n",
    "    \n",
    "    return neg_samples\n",
    "\n",
    "def edge_index(batch,size): #выбираются ребра только для батча и только для вершин внутри батча\n",
    "    adj=batch.adj_t\n",
    "    t=(adj.to_torch_sparse_coo_tensor()).coalesce()\n",
    "    ind = torch.tensor(range(size))\n",
    "    edge_index = t.indices()\n",
    "    first=((edge_index[0]<len(ind)).nonzero(as_tuple=True)[0])\n",
    "    second=((edge_index[1]<len(ind)).nonzero(as_tuple=True)[0])\n",
    "    new_indices=(torch.tensor(np.intersect1d(first,second)))\n",
    "    edge_index1 =  edge_index[0][new_indices]\n",
    "    edge_index2 = edge_index[1][new_indices]\n",
    "    return (torch.stack([edge_index1, edge_index2], dim=0)),ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader,num_negative_smples):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch,*args in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x[:args[0]], batch.adj_t,*args)\n",
    "        e_index,ind=edge_index(batch,args[0])\n",
    "        #print('edge index construct',datetime.now()-d)\n",
    "        pos = e_index.t()\n",
    "        \n",
    "        neg = neg_samples(e_index,ind,num_negative_smples)\n",
    "        samples = (pos,neg)\n",
    "        loss = model.loss(out, samples)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        total_loss+=loss\n",
    "    return total_loss/len(loader)\n",
    "def test(y_true,model,data,val_edge_index):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.adj_t)\n",
    "\n",
    "    y_pred = []\n",
    "    for x in list(zip(*val_edge_index)):\n",
    "        y_pred.append(float(torch.sigmoid(torch.dot(out[x[0]],out[x[1]]))))#print(torch.sigmoid(torch.dot(out[x[0]],out[x[1]])))\n",
    "    \n",
    "    return roc_auc_score(y_true,torch.tensor(y_pred).detach().numpy()) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = datetime.now()\n",
    "model = Scalable(num_nodes=len(data_init.x), in_channels=len(data_init.x[0]), hidden_channels=128,out_channels=128, num_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay = 1e-5)\n",
    "schedular  = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "num_negative_smples=4\n",
    "losses=[]\n",
    "scores=[]\n",
    "for epoch in range(353):\n",
    "        d=datetime.now()\n",
    "        loss=train(model,loader,num_negative_smples)\n",
    "        losses.append(float(loss))\n",
    "        print(epoch,loss)\n",
    "        #scheduler.step(loss)\n",
    "        #score=test(y_true_val,model,data,val_edge_index)\n",
    "        #scores.append(score)\n",
    "        print('one epoch',datetime.now()-d)\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "#plt.plot(torch.tensor(scores).tolist())\n",
    "#plt.show()\n",
    "print(datetime.now()-d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model_parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сам инференс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### принимает параметры: \n",
    "* vertex = tuple(id, text_emb)\n",
    "\n",
    "* neighbors = [(id, text_emb), (..)] (list of tuples)\n",
    "\n",
    "* neighbors_of_neighbors = [(id, text_emb), (..)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "x=model2.inference(vertex,neighbors,neighbors_of_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = igraph.Graph.TupleList(rels, weights=False, directed=True)\n",
    "igraph.summary(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import math\n",
    "# plot tree\n",
    "init_notebook_mode()\n",
    "def plot(G, annotations=False):\n",
    "\n",
    "    lay = G.layout_fruchterman_reingold(grid=\"nogrid\", niter=1000)\n",
    "    nr_vertices = len(G.vs)\n",
    "    position = {k: lay[k] for k in range(nr_vertices)}\n",
    "    Y = [lay[k][1] for k in range(nr_vertices)]\n",
    "    M = max(Y)\n",
    "    labels = [x['name'] for x in G.vs()]\n",
    "    es = igraph.EdgeSeq(G) # sequence of edges\n",
    "    E = [e.tuple for e in G.es] # list of edges\n",
    "\n",
    "    L = len(position)\n",
    "    Xn = [position[k][0] for k in range(L)]\n",
    "    Yn = [2*M-position[k][1] for k in range(L)]\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    for edge in E:\n",
    "        Xe+=[position[edge[0]][0],position[edge[1]][0], None]\n",
    "        Ye+=[2*M-position[edge[0]][1],2*M-position[edge[1]][1], None] \n",
    "\n",
    "\n",
    "    #Create Plotly Traces\n",
    "\n",
    "    lines = go.Scatter(x=Xe,\n",
    "                       y=Ye,\n",
    "                       mode='lines',\n",
    "                       line=dict(color='rgb(210,210,210)', width=1),\n",
    "                       hoverinfo='none'\n",
    "                       )\n",
    "    dots = go.Scatter(x=Xn,\n",
    "                      y=Yn,\n",
    "                      mode='markers',\n",
    "                      name='',\n",
    "                      marker=dict(  colorbar=dict(\n",
    "                                        title=\"Modularity\"\n",
    "                                    ),\n",
    "                                    colorscale=\"Viridis\",\n",
    "                                    \n",
    "                                  \n",
    "                                    line=dict(color='rgb(50,50,50)', width=1)\n",
    "                                    ),\n",
    "                      \n",
    "                      hoverinfo='text',\n",
    "                      opacity=0.8\n",
    "                      )\n",
    "\n",
    "    # Create Text Inside the Circle via Annotations\n",
    "\n",
    "    def make_annotations(pos, text, font_size=10, \n",
    "                         font_color='rgb(0,0,0)'):\n",
    "        L=len(pos)\n",
    "        if len(text)!=L:\n",
    "            raise ValueError('The lists pos and text must have the same len')\n",
    "        annotations = go.Annotations()\n",
    "        for k in range(L):\n",
    "            annotations.append(\n",
    "                go.Annotation(\n",
    "                    text=labels[k], # or replace labels with a different list \n",
    "                                    # for the text within the circle  \n",
    "                    x=pos[k][0], y=2*M-position[k][1],\n",
    "                    xref='x1', yref='y1',\n",
    "                    font=dict(color=font_color, size=font_size),\n",
    "                    showarrow=False)\n",
    "            )\n",
    "        return annotations  \n",
    "\n",
    "    # Add Axis Specifications and Create the Layout\n",
    "\n",
    "    axis = dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "                zeroline=False,\n",
    "                showgrid=False,\n",
    "                showticklabels=False,\n",
    "                )\n",
    "    ann = []\n",
    "    if annotations:\n",
    "        ann = make_annotations(position, labels)\n",
    "    layout = dict(#title= 'Tree with Reingold-Tilford Layout',  \n",
    "                  height=900,\n",
    "                  annotations=ann,\n",
    "                  font=dict(size=12),\n",
    "                  showlegend=False,\n",
    "                  xaxis=go.XAxis(axis),\n",
    "                  yaxis=go.YAxis(axis),          \n",
    "                  margin=dict(l=40, r=40, b=85, t=100),\n",
    "                  hovermode='closest',\n",
    "                  plot_bgcolor='rgb(248,248,248)'          \n",
    "                  )\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    data=go.Data([lines, dots])\n",
    "    fig=dict(data=data, layout=layout)\n",
    "    #fig['layout'].update(annotations=make_annotations(position, labels))\n",
    "    iplot(fig, filename='Tree-Reingold-Tilf')\n",
    "    # use py.plot instead of py.iplot if you're not using a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data,optimizer,epoch):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(data,data.adj_t)\n",
    "        samples = Sampler.sample(nodes)\n",
    "        loss = model.loss(out, samples)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna todo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "        data,mapping_new_to_old=data_loader()\n",
    "        print(data)\n",
    "        perm, ptr = metis(data.adj_t, num_parts=40, log=True)\n",
    "        data_train = permute(data, perm, log=True)\n",
    "        loader = SubgraphLoader(data_train, ptr, batch_size=10, shuffle=True)\n",
    "        len(loader)\n",
    "\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [64,128])\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [2,3])\n",
    "        num_negative_samples=trial.suggest_categorical('num neg samples', [1,2,3,4,5,6,7,8,9,10])\n",
    "        model = Scalable(num_nodes=len(data.x), in_channels=len(data.x[0]), hidden_channels=hidden_layer,out_channels=out_layer, num_layers=size)\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-4,1e-2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        for epoch in range(50):\n",
    "            loss = train(model,loader,num_negative_smples)\n",
    "        score=test(y_true_val,model,data,val_edge_index)\n",
    "        \n",
    "        trial.report(score,epoch)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective,n_trials = 20)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(\" Value: \", trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\" {}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
